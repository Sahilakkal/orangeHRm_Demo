import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Define the dataset
data = {
    'Domain': ['Enterprise Software', 'Enterprise Software', 'Enterprise Software', 'Enterprise Software', 'Enterprise Software', 'Enterprise Software', 'Enterprise Software', 'Enterprise Software', 'Enterprise Software'],
    'Requirements': ['User Management', 'User Management', 'User Management', 'Financial Management', 'Financial Management', 'Financial Management', 'Inventory Management', 'Inventory Management', 'Sales and Order Management'],
    'User Story': [
        'As an administrator, I want to be able to create new user accounts, assign roles, and manage permissions easily',
        'As a user, I want to be able to reset my password securely',
        'As a manager, I want to view user activity logs for auditing purposes',
        'As a finance manager, I want to generate financial reports, such as balance sheets and income statements, for accurate financial analysis and decision-making.',
        'As an accountant, I want to record and reconcile financial transactions efficiently.',
        'As a CFO, I want to monitor budget utilization and track key financial metrics.',
        'As a warehouse manager, I want to track inventory levels in real-time, receive alerts for low stock, and generate purchase orders automatically when stock reaches a reorder point.',
        'As a procurement officer, I want to maintain a centralized product catalog with SKU information and pricing details.',
        'As a sales representative, I want to create and manage customer orders efficiently, track their status, and generate invoices for timely payment processing'
    ]
}

# Create a DataFrame from the dataset
df = pd.DataFrame(data)

# Preprocess the dataset
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['Requirements'])
X = tokenizer.texts_to_sequences(df['Requirements'])
X = pad_sequences(X)

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['User Story'])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the neural network model
model = Sequential()
model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=X.shape[1]))
model.add(LSTM(128))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=16)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print('Loss:', loss)
print('Accuracy:', accuracy)
